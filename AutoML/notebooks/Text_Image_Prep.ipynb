{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> We want numerical feature vectors with a fixed size rather than the raw text documents with variable length </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "import matplotlib.pyplot as plt            # library for visualization\n",
    "import random                              # pseudo-random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Twitter dataset\n",
    "The sample dataset from NLTK is separated into positive and negative tweets. It contains 5000 positive tweets and 5000 negative tweets exactly. The exact match between these classes is not a coincidence. The intention is to have a balanced dataset. That does not reflect the real distributions of positive and negative classes in live Twitter streams. It is just because balanced datasets simplify the design of most computational methods that are required for sentiment analysis. However, it is better to be aware that this balance of classes is artificial.\n",
    "\n",
    "In a local computer however, you can download the data by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\Tigran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the text fields of the positive and negative tweets by using the module's `strings()` method like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets:  5000\n",
      "Number of negative tweets:  5000\n",
      "\n",
      "The type of all_positive_tweets is:  <class 'list'>\n",
      "The type of a tweet entry is:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))\n",
    "\n",
    "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
    "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is stored in a list and as you might expect, individual tweets are stored as strings.\n",
    "\n",
    "You can make a more visually appealing report by using Matplotlib's [pyplot](https://matplotlib.org/tutorials/introductory/pyplot.html) library. Let us see how to create a [pie chart](https://matplotlib.org/3.2.1/gallery/pie_and_polar_charts/pie_features.html#sphx-glr-gallery-pie-and-polar-charts-pie-features-py) to show the same information as above. This simple snippet will serve you in future visualizations of this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEeCAYAAACNLn6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV5YH/8c9z7812k3DZMYAS0IALFAExVau2WuvS1r1T207rTOvYZbqNbUemv7ZzbafWtjNdZqar2mrtqNXWJZa6WxG3iCKgFUNEUGQTyJ6b5G7P749zAgECJJDkufee7/v1ui/gLsk3Ifme5z7nnOcYay0iIhIcIdcBRERkZKn4RUQCRsUvIhIwKn4RkYBR8YuIBIyKX0QkYFT8IiIBo+IXEQkYFb+ISMCo+EVEAkbFLyISMCp+EZGAUfGLiASMil9EJGBU/CIiARNxHUDkUFQvWlwEVPW5Td7jz0lAKd7Peu+taI55/a37Sr5xBJDuc0v5f7YDm/3bpj3+3AxsJ96qC1lI3lLxS86rXrR4NLDAvx3N7uU+DjCD/ZgG24G3UTgYKeKxLezaGLwFrAReAF4m3po6yI8rMiJU/JJT9ij53tuRQ/15bE/nOEoO+uVFwOH+bU89xGOr8DYCvTdtDCSnqPjFmepFiyuAWoa55PtnB/0uYYBKgIX+rdeeG4PngZWaLhJXVPwyoqoXLZ4KfBA4H3gPHMK4+1AYM5Kl29/GYAvx2GKgDniYeGvXCOaRgDO62LoMt+pFi+fjFf35wDzHcQCYk1rVdF/ldWNd5/B1AY/gbQTuI9661XEeKXAa8cuQq160uBg4A6/oPwhMdZso55XhfZ8+CFjiseeA+4A64q0vOU0mBUkjfhkS1YsWh4EPAH8PnA1Uuk20fzk24t+fdcA9wA3EW19xHUYKg4pfDkn1osWTgCuAK4EjHMcZsDwq/r6WAD8H7tZRQnIoNNUjB6V60eJTgc9Zay82xhS7zhMQp/u3zcRjNwC/It660XEmyUMa8cuA+Ydfftxa+1ljzBzXeQ5Fno7495TG2xfwc+Ktj7gOI/lDI345oOpFi4/DG91/3BhTacxwHQIvgxQBLgIuIh5rAH4B3ES8tdVtLMl1GvHLPlUvWrzQWvtdY8xZrrMMtQIZ8fcnAfwSuJZ46w7XYSQ3qfhlL9WLFs+yNnutMaGLXWcZLgVc/L3agB8CPybe2uk6jOQWFb/sVL1o8RSbzXwHE7rcGFPQS3YHoPh7bQG+A1yvI4Gkl4pfqF60eIzNZv4fxnzemJCbJRRGWICKv9da4JvA7VojSAp6VCf7V71ocXTa1fd93Wazb5hQ+CtBKf2AOhK4FVhOPHaO6zDilo7qCaDqRYsj1torsNlvm1B4wuBXs5c8djxwP/HY48Ai4q31jvOIAxrxB0z1osXzbSb9kjHmFyYUnuA6jzjzbuBZ4rEbiMdGuQ4jI0vFHxDVixYXH/HlO35sbXaZCUeOdp1HcsangJeJx852HURGjoo/AA7/0u212WRXY6i0/MvGhPR/Lns6HHhAo//gUAkUsOpFi4sP/+Kt/xsqLX86VFyWNwuoiTMa/QeEir9A9Y7yw9HYP2uUL4Og0X8AqBAKjEb5MkQ0+i9gKv4ColG+DDGN/guUyqFATP3sb64OlZQ/pVG+DINPAcuIx2a5DiJDQ8Wf50af9vGyKZ++fnEkNuk6EwqFXeeRgjUTqNdZv4VBxZ/Hxp335ZqK2We+XDRm8nmus0ggxIDFxGNfdR1EDo2KP09NvOSb55bPPGlZZNSEGa6zSKCEgB8Sj/2OeExrO+UpFX+eidbUmkmXfXdR2fQF94ZKK2Ku80hgfRxYQjxW5TqIDJ6KP49Ea2qLYidfdlvptLnXmkhRkes8Eni1wPPEYwtdB5HBUfHniTFnfGrimPd8qr6kauaHjS56K7ljMvAE8djHXAeRgVPx54Hx53/thIrjzlhZNHbKPNdZRPpRCvyeeOwHxGPqlDyg/6QcN+6cz78/OmPhY+Hy0Ye5ziJyAF8Dfks8psOKc5yKP0dFa2pDY8644sryY07/Q6i0vNJ1HpEB+gRwK/GYLvKUw1T8OShaUxsumXLs1ZXHn/OTUEm03HUekUH6O+BO4rFi10Gkfyr+HBOtqY2UHDHnW5ULPvitUHFZmes8IgfpQuAe4rFS10Fkbyr+HBKtqS0uOXz2NZXzzrs6VFSiXxjJd+cC96n8c4+KP0dEa2pLiifP+vfKee+/KhQp0RmRUijeC/xR0z65RcWfA6I1tSXFE2fERy244F800pcC9H7gdu3wzR0qfseiNbXFReOn/b9RJ178xVBxqeb0pVBdBNyi4/xzg/4THIrW1BZFxk79Wqz20n8JlUSjrvOIDLPLgBtdhxAVvzPRmtpIqKT807ETL7oqVFpe4TqPyAj5B+Kxb7oOEXQqfgeiNbVh4BOjai/9Srh8zFjXeURG2DXEYxe6DhFkKn43zq+cd94XiidMq3YdRMQBgzffP9t1kKBS8Y+waE3twrLpC75QOn3B8a6ziDhUAdQRj41zHSSIVPwjKFpTW100ftqiirlnn6KVlUWYjre0gw7zHGEq/hESrakdEyqL/WvsnZeeacIRncwi4nkP8FPXIYJGxT8CojW1xYQinx99ymUXhErKdblEkd19jnjs065DBImKf5hFa2oN8NHYiRd/JBKbNNl1HpEc9T/EY6e5DhEUKv7hd0b5sad/umTK0ce4DiKSw4rw1vSZ5jpIEKj4h1G0pvbY4sNqrorOOvVE11lE8sAEvKWctQ9smKn4h0m0pvYwEy76UuX8D9SaUEjfZ5GBOR7Qmb3DTIU0DKI1tVHgS5UnnL8wXFap45RFBmcR8dgC1yEKmYp/eFxSXDVzdsmUY3WSlsjgRfAu2q4pn2Gi4h9i0ZraYwgXvW/U/A+80+gsLZGDNQdN+QwbFf8Q8qd4rhh1wgVHh0orxrvOI5LnNOUzTFT8Q+uS4qqZNSVTjtEPq8ih05TPMFHxD5E+UzwnaYpHZMhoymcYqPiHgKZ4RIaVpnyGmIp/aGiKR2T4aMpniKn4D5E3xRPRFI/I8JoDfMN1iEKh4j8EvVM8FXPOOlxTPCLD7l+Jxw53HaIQqPgPzSWmODqhbNrcha6DiARACXCN6xCFQMV/kKI1tdOBMyvnnTfNRIqjrvOIBMQniMe00u0hUvEfBH+N/Q+Fy8fYkqqZ73SdRyRAwsC1rkPkOxX/wTkGOLZi3nnH6jKKIiPuQuKxk1yHyGcq/kGK1tSGgA9HxlRRPGG6Dt8UceM61wHymYp/8I4HqivnnjvfhEJh12FEAuo04rFzXYfIVyr+QYjW1BYBHymedKSJjJ0y23UekYD7HvGYzp05CCr+wXknMKFizllaclnEvbnAR12HyEcq/gGK1tSWAh8qPeIdxZHYxBrXeUQEgG8TjxW5DpFvVPwDdzpQWX7M6e9yHUREdpoBXOk6RL5R8Q9AtKa2ErioZMqxJlwxRqeMi+SWL2muf3BU/APzPqCo7KgTdQ1dkdxTA5zlOkQ+UfEfQLSmtgI4JxQd3VI0dspxrvOISL8+5zpAPlHxH9gJQLj8mNPmmFA44jqMiPTrA1q5c+BU/Pvhn6V7HtBUUjXzBNd5RGSfwsCnXYfIFyr+/ZsJTCg7qvawUEl0jOswIrJfV+jQzoFR8e/fe4Husurjtd6+SO6bBFziOkQ+UPHvQ7SmdhwwPzJmcjI8SidsieQJ7eQdABX/vp0E2PKj3zVfyzOI5I1Tice0jtYBqPj74S/Gdjbhoh1FE2fMc51HRAZFo/4DUPH3bzZQUX70u44MRYrLXYcRkUH5e+KxStchcpmKfw/+ZRXPBdpLJh8913UeERm0SuBi1yFymYp/b5OBmlBpRWe4Yly16zAiclAucB0gl6n493YKkCmdPv9IXWFLJG+9j3isxHWIXKXi78M/U/ddwPaSSUfNcp1HRA5aOXCG6xC5SsW/u6lABSbUE4lN0rH7IvntfNcBcpWKf3fHAZROm3uEiRSVuQ4jIofkg64D5CoV/+5OBppLJh+taR6R/DeFeGyB6xC5SMXv85domAq0F42douIXKQya7umHin+XWYAtnjhjfKgkOtZ1GBEZEir+fqj4dzkJ6Cw5Yo5G+yKF43hdoGVvKn4gWlMbBY4BmovHHaHiFyks2sm7BxW/5yggFK4YWxoqHz3VdRgRGVKa7tmDit+zAEiWTD1umpZgFik4pxKP6Sz8PgJf/NGa2giwEGgqGl1V5TqPiAy5KHC06xC5JPDFDxwOlADJcOW4ya7DiMiw0PH8faj4vdU4DUA4GtOIX6Qwqfj7UPHDTKAnMmZKzESKo67DiMiwUPH3oeL3TtxqL540Q9M8IoXreOIx9Z0v0N+IaE1tGTAR6NKOXZGCVo528O4U6OIHqgALWO3YFSl4J7gOkCtU/NqxKxIUmuf3Bb34tWNXJDhU/L6gF7927IoEh3bw+gL7TdCOXZHA0Q5eX2CLnz47dkPloye4DiMiI+JY1wFyQdCL3wCEiksrHWcRkZGhaV2CXfw1QA+AKVLxiwSEip9gF/9hQDeAiRRXOM4iIiND+/MIdvGPBXrClePKjQkF+fsgEiQa8RPQ4o/W1BpgDJAMV4zXaF8kODTiJ6DFD5QBYSAbLh+t+X2R4NCIn+AWfwWQBQiXjVLxiwTHGOKxUtchXAtq8e8s+1BZpYpfJFgCP90T5OL3juEviWqOXyRYVPyuAzhSgV/8pjiqEb9IsAR+nj+oxT8Wf44/pJO3RIJGI37XARyZACQBTFFJueMsIjKyDnMdwLWgFv84/OUaMKEit1FEZIQF/qieyIGeYIzJAC/5z10NXG6tTQzmkxhjbgB+ZK19xRjzdWvttX0ee9pae/Igcx+qcfSO+I3JuY3fW7/4JKHiMgiFMKEwVZf/hExXO9vv/T7ptq1ERk1i/IWLCJfuvV+646VHaX3mdgBiJ11GxZwzsekUb9/1HTLt26mc934q578fgB0P/A+V886jeNKRI/r1iVvVP2mnssQQNhAJwfNXVtDUZfnwHxOsb7FUjzbccWmUMWVmr9fevCLJfyxNAvCNU4u5/PhietKWC25P8Fab5XMLi/ncwmIArryvi8+eUMy8qvCIfn0DcMDe648xxuL12Ff8f38VqLDWxocwGyPRkQMpvS5r7fHW2tl4ZfmZwX4Sa+0V1tpX/H9+fY/HRrr0wdu5mwIgB4sfYNJHrmXyP/4PVZf/BIC2Z++ktHouU668ntLqubQ9e+der8l0tdP61K0c9vEfcdgnfkzrU7eS6e6ga91yig87iqpP/i/tKx8AIPn262CtSj+g/np5lBWfqeD5K73Bw3VP9nDm9AiNX6jgzOkRrnuyZ6/XNHVZrlnSQ/0V5Tx3RTnXLOmhucvy4No0C6rCrPpsOb9+wdsorNySIWvJxdIHONh3+T3AxcaY8UMZph/D3pGDLb2lwFEAxpirjDEv+7cv+/eVG2MWG2NW+vd/2L//cWPMCcaY64AyY8wKY8z/+Y91+H/+wRhzXu8nMsbcZIy5xBgTNsb80BizzBizyhjzaf/xKmPME/7HetkYc+ogvo4w3lr8kCfr9CReq6d89pkAlM8+k0Tjs3s9p3vdckqr5xEuqyRcWkFp9Ty6X38BEwpjUz2Qzex8bsvS3xN718dGLL/ktnsb0lw+1+vDy+cWcU9Deq/nPPhamrNmRBhbZhhTZjhrRoQHXktTFIKuNKSzu577zb/28O33lIxU/ME6qBE/kAZ+DfzLng8YYyYYY/7k99QyY8wpfe5/2Biz3BjzK2PMG70bDmPMPcaYF4wxfzPGXOnfN2QduT8DLj1jTAQ4F3jJGLMA+EegFngn8E/GmHnAOcAma+1c/x3CA30/hrV2EbveQezZOrcDvRuKYuBM4C/Ap4BWa+1CYKH/uaYDHwUetNYeD8wFVgz0a/G/but/ZblX/Mbw9h3fYvNNX6J9hfctzHS2EKkYC0CkYizZzpa9XpZu30F41K7BSLhyHOn2HZROn0ems4XNv/sKsdpLSDTWUzzpKCKV40bm65GcYgy875YEC37dsXOEvrUjS1Wl96tQVRni7c7sXq/b2J7l8D5XLpw6KsTG9ixnHRlhS0eW2hs6+ddTSqhrSLGgKszkytz71fIdbPED/Az4mDEmtsf9PwV+7PfUJcAN/v3/DjxmrZ0P3A0c0ec1n7TWLgBOAL5ojBk3xB25TwP5BpQZY3pLdSlwI/BZ4G5rbacf4i7gVLyi/09jzPeBP1trlw7g4/e6H/hvY0wJ3gbkCWttlzHmfcA7jDGX+s+L4a2lvwz4jTGmCLjHWjuY4u8z4s+94j/sYz8gUjmOTGcLW//wDYrGTR3gK+1e9xgDJhRmwvlf856RSbP1jm8x8ZJv0vTo9WTatlE++0yiNbVD+BVILnvqk+VM9sv9rFsSHD1+YL8Cdu8fLwwQCRluvSQKQCpjOfv3Ceo+EuWqB7t5szXLJ+YWcf6snDqG4qDDWGvbjDG/A74IdPV56L3Ascbs3C8yyhhTCbwLuMh/7QPGmOY+r/miMeYi/++H4/Xajv18+sF25Lp9faDBzPEfb639grU2iX/y056stWvwrmT/EvA9Y8y3BvDxe1/bDTwOnI23Vbvdf8gAX+iTYbq19iFr7RPAacBG4BZjzCcG8nn8lTl3FX8O6h2Jh8tHE515Ej2b1hAuH026owmAdEcTofLR/bxuPJm27Tv/nWnfQbhi91F9+4uLqZh9Jj0bX8WEixh/wdU7dwZLMPSOxCeWh7jo6AjPbcwwqSLE5nZvlL+5PcvE8r2rYeqoEBtad70TeKstu9eo/ufLklw+t4hnNmQoDsMfLi3jP57Ye3+BY4f6u/8TvFF230PBQ8BJfXpqirW2nX10pTHm3Xgbi5OstXOBFznA0UaD7cj9fayDHe0+AVxojIkaY8rxtmhLjTGTgYS19vfAfwLz+3ltyh+l9+d2vCmkU4EH/fseBD7b+xpjzEx/X8I04G1r7fV470L6+1z96TPNA1i793tah7LJbrI9iZ1/7173IsUTphE9qpbOlx8FoPPlR4ketfcIvXT6fLrWv0imu8Pbqbv+RUqn7/q2ZLo76HptGeWzz8Cme/y3AwabTo3MFyfOdSYt7T12598fWpth9sQw58+McPNK7+fg5pUpLpi192TA2UdFeOj1NM1dluYuy0Ovpzn7qF3Pa+6y/LkxzSfmFpFIWULejxfde+8ucO2QfuCttU3AHXjl3+sh4PO9/zDGHO//9Ung7/z73oe3HDx4o/Jma23CGHM03pT5znxD0ZH7+xoOaq7LWrvcGHMT8Jx/1w3W2heNMWcDPzTGZPG+uZ/t5+W/BlYZY5b3M4f1EPA7oM5/ZwHeXFk1sNx476O2ARcC7wa+ZoxJAR3AgEb87LUFzmYhlDOHHmQSLWy76z+8f2SzlB97OmUzFlBcVcP2e6+jY9VDREZNYPwF/wZAz+ZGOlbcz7hzv0i4rJLRJ3+YLTd7+55Gn3wZ4bJdJya3PnUbsZM/jDGGsunzaV++mM03fp6KeeeO+NcpbmzttFz0B29gkc7CR2cXcc5RERZODvF3f+zixhdTHBEz3Pkhb+rm+U0Zfvl8khvOL2NsmeGbp5Ww8PoOAL51Wglj+xzy+e0lPXzj1BKMMZx9VISfLUsy5xedfGZB8ch/ofs3FJui/6JP0eNN/fzMGLMKr1efwDsC8hrgNv9AlyXAZqAdb1r8M/7zG4C+R2sMVUfuk7H9TdwVsGhNbQjvHcIbABMu/LdFJlyUs4cfyPCYk1rVdF/ldWNd5xAnfk689Z9H4hP58/EZa23aGHMS8Av/gBSnDmXvdr6y9B31W5vZ91NFpACN5OTTEcAd/omiSeCfRvBz71Pgij/RWG+jNbUZvPK31tpsv3tfRKRQjdhOLWttIzBvpD7fQOXcoYwjpLf4IZvRnk2RYOl0HcC1oBZ/Fr/4baq73XEWERlZm10HcC2oxZ/G/9qzqe4Ox1lEZGSp+F0HcKQd/+y9bE9CI36RYNnkOoBrQS3+HUAxQLanU8UvEiwa8bsO4Miu4u/uUPGLBEcW2OI6hGtBLf5tQAlANtGqOX6R4NhOvDX3FpEYYUEt/mb8rz3T2awRv0hwBH5+H4Jb/O14x/KTbt+u4hcJjsDP70Owix+AbKK122YzgX/rJxIQGvET3OLvoM96PTad1Dy/SDBoxE9wi3+3CyTYpM7eFQkIjfgJbvH34C3UFAbIprra3MYRkRGy0XWAXBDI4k801lu8I3uKATLtO7a6TSQiI2SV6wC5IJDF72vCP5Y/1bxRb/9ECt8O4q3rXYfIBUEu/o1AGUByy2va4SNS+F5wHSBXBLn41+Iv1JbpaEpkk12tjvOIyPBS8fuCXPyb8S7DCEAm0aJRv0hhU/H7gl784B/WmWnbrnl+kcKm4vcFtvgTjfVJvHn+ctAOXpEC16Qdu7sEtvh9a4BK0A5ekQKn0X4fQS/+19AOXpEgUPH3EfTi1w5ekWBQ8feh4vdoB69IYVPx9xHo4tcOXpFAaCLeus51iFwS6OL37dzB2/3my29qbX6RgvOI6wC5RsXfZwevTSZSmfYdGhmIFJY61wFyjYp/j2Vak9vWN7gKIiJDLg38xXWIXKPi94q/AygF6F7/4hpr7f5fISL54knirc2uQ+SawBd/orE+CzwDjAVIt25tz3a1aSevSGHQNE8/Al/8vhX4V+MCSO3YoOkekcJwr+sAuUjF71kLZPDLv3vD31T8IvnvFeKtr7sOkYtU/Ow8nn8F/nRPcnPDVi3fIJL37nMdIFep+HdZhn9FLoB08+Y1DrOIyKHT/P4+qPh3acBbusEA9Gxeo+kekfz1NvCs6xC5SsXvSzTWt+HN9ccAute/uN5m0j1uU4nIQVpMvDXrOkSuUvHv7mlgFIDNpDLp1q2vOc4jIgfnHtcBcpmKf3er8ad6ALrfXLXcYRYROTib0dm6+6Xi390WYAcQBehau+z1bE/nDreRRGSQrifeqsUW90PF30eisd4CS4Bxvff1bFrzvLtEIjIY1to08GvXOXKdin9vz+J9XwxA5+olK2w2k3IbSUQGwhhTR7x144GfGWwq/j0kGuu34Z3MNQEg29XWnWp662W3qURkgH7uOkA+UPH372H6nMzV9dpzyxxmEZEBsNa+Srz1Udc58oGKv38NQBP+JRl7Nq7enEm06O2jSA4zxvzSdYZ8oeLvR6KxPoN3ONjOnbzdG17RqF8kR1lrE8BNrnPkCxX/vi0DsvgrdiYalv7NppNdbiOJSH+MMbcSb9XCigOk4t8HfwmHp4CJADbVk05uW/+i21Qisg/aqTsIKv79exwo7v1HouGp53VZRpHcYq19lnirBmWDoOLfv/XABvyF21I7NjSnWza/4jSRiOzGGPMD1xnyjYp/P/wzeRcDo3vv63jpkceszWrVP5EckLW2nnjr3a5z5BsV/4GtBLqBEoDUtvU7UtvfXOE2kogAhIy52nWGfKTiP4BEY3033hKvk3rv61j54OM2m9EiUCIOpTL2EeKtS1znyEcq/oFZAnTgr9qZbt3antzyWr3bSCLBZa21RWHzNdc58pWKfwD8Uf+d+Id2ArSvfOBJm0l1u0slElzpLHcQb9WU60FS8Q/cs8A2/Ct0ZROt3d1vvfKk20giwZO1Nl0UNl93nSOfqfgHKNFYnwJuo88yDh0rH6zPprrb3aUSCZ6s5Xrira+7zpHPVPyDswLv2P6xADbVne5+Y6V2LomMkKy1XZGQucZ1jnyn4h+ERGN9Frgd/4QugI6XHnlRl2cUGRnW8iPirVtd58h3Kv7BexV4md4dvdlMNrF22WNOE4kEQCZrm8MhnaU7FFT8g+SfzftHvEM7DUBi9ROvpNu3a85RZHh9lXhrm+sQhUDFfxASjfXrgOfoc1JX27J762wmnXSXSqRwdSbtkvC3237jOkehUPEfvLvxVu6MAKSbN7Z2rVv+kNtIIoUnmbHdRWE+5jpHIVHxH6REY/1mvKUcpvbe17HygRc05SMytFq67dXF32nTpU+HkIr/0DyAt2zz+N47NOUjMnSau2z9xB+2/7frHIVGxX8IEo31SeAGvIuya8pHZAj5UzyXus5RiFT8hyjRWP8G3ny/pnxEhlBLt7264tq2t1znKEQq/qGhKR+RIaQpnuGl4h8CmvIRGTqa4hl+Kv4hoikfkaGhKZ7hp+IfWv1M+dxTZ9PJhLtIIvljRyK7VFM8w0/FP4T6n/LZ1Nq+6qE7dYF2kf1r6bZbkhne7zpHEKj4h1ifKZ/De+/rXrd8fdfrLzzgLpVIbutK2Z6VWzIfrPqvdl3fYgSo+IfH/XireE7uvaNjxf3Lkm+ve95dJJHclMla+8Qbma+cflOnfj9GiIp/GPhX6/oF3gXax/be3/L0bfenO5recBZMJAc9tzHzm58tS/7cdY4gUfEPk0RjfQvwU7zlm8sAyKSzrU/dekc22dXiMptIrli9LfPM955MfqauIWVdZwkSFf8w8uf7fwlU4e/szXQ0Jdqev/d2m02nnIYTcWxTe3bDH19JnVfXkEq7zhI0Kv5hlmisfx64C29nrwFIbl6ztXP10rut1SBHgqm123Y8+nr63G/+tUfvfh1Q8Y+M+4Bl9Dm5K/Hq0tU9G1frQu0SOMmMTT/xRvryj9/d9TfXWYJKxT8CEo31GeA3wGZ6r9ULtNX/8fFU8+bVzoKJjDBrLU9vyFz3wdsSd7nOEmQq/hGSaKxPAL1nJFb23t+y9Ja7dKSPBMXTGzK3/+iZ5Ldc5wg6Ff8ISjTWv41X/uPwLtuITXWnmx//7a2ZzmatTSIF7fH16Ye+/1TyH3QEj3sq/hGWaKx/FbgZb74/AmB7OpPNS276fSbRutlpOJFh8vj69LM/eiZ5WV1Dqsd1FlHxu/I43pE+RwBhgGxXe0/zkptvyXS1b3UZTGSoPflmevmPnkleWteQanadRTwqfgcSjfUWuBeoA6bh/z9kEy1dLU/87neZ7o5tLvOJDJVn30qv+sFTyYvqGlK6WHoOUfE74pf/XXjr+lTj/19kOnYkWpbcdFOmq22Lw3gih2zpG+kV1y5NXlDXkHrTdRbZnYrfoW1Hj/QAAAneSURBVERjfRb4A/AIfUb+mY6mRPPjv705k2jRKEny0qOvp5f/8Onkh+oaUutdZ5G9qfgd88v//4C/stu0T2t3819/e0umo3mDy3wig/XAa6llP61PfqSuIfWa6yzSPxV/DvBP8LoFeBhv2sfb4dvd3tP01xtvSbfvWO8uncjA3deQeubny1IfrWtIrXGdRfZNxZ8j/PK/FfgL3sg/DGCTiVTzY9f/Prn9zRUu84nsTypj0zetSD58/fLUxzTSz30q/hzSZ87/Xrzy947zTyczLUtuurdr/YsPWa3sJjmmvcd2fO/JnrvuWp2+oq4htc51HjkwFX+O6XO0z514x/mX9j7W/sJ9z3SsfPD/bCbV7SqfSF9vtWW3fO3h7tue35S9Skfv5A8Vfw7yy//PeFfxmgiM7n2sa+1za1uevPX6bHfndlf5RABe2JRZc9WD3Tdsarf/puP084uKP0clGuttorH+GeC7eP9Ph/U+ltr+RlPTY7++Id36tuZSZcRlrbV3rU4tu2ZJz391p/luXUNqh+tMMjgq/hyXaKxfC1wDbMKb+jHgLfHQ9Oivbu3ZvOZpl/kkWLrTtvsnzyYfuWlFKg7cUNegacd8pOLPA4nG+h3A94FngOlAEQDW2tanb3+489Un77bZjC5fJ8NqRyLb9I3Heu59fH3mq3UNqb/UNaSyrjPJwVHx54lEY30PcCNwG97KnuW9j3X+7bFVbcvuuSmb6m53lU8KW+OOzJtXPdh9y5od2a/UNaRWuc4jh8bo6MD8E62pnQN8HkgBO3fyhqKjy2InXnxu0bipc5yFyxNzUqua7qu8bqzrHLkumbHJe15Nv/D7Vam7gF/VNaQ0uCgAKv48Fa2pnQx8GRgD7HZERXTWKbOis971gVBRSYWTcHlAxX9gG1qz63/wVM/yN1rtn4A76xpSKdeZZGio+PNYtKa2EvgnYC7e9Xx37mjT6H//VPz7lszY5H0N6WduXplai3fRoKW6alZhUfHnuWhNbQg4DfgYkAZ2u5CLRv/9U/H3zx/lv/BGq10J3FjXkNrkOpMMPRV/gYjW1E4E/gGYjXfo5+6j/9qLzy0aq9F/LxX/7lIZm7xvTfqZm1ek1lq4A3i0riGlI8UKlIq/gGj0P3Aq/l00yg8eFX8BOuDo/8SLzykaN/UdjuLlBBU/JDO2589r0s9qlB88Kv4CdaDRf8nUYyeXH/vu90Yqx093kc+1IBd/OmvTyzdnXvjFstS6HV32FTTKDxwVf4Hb3+gfoOzIhTOiM09+bzgaq3IQz5kgFn/WWrt6W3bFr15IvrS+xabRKD+wVPwB0Gf0fxnecg9b8E7+2qn8mNOPKzvyhDNCJeWBKMOgFf/rzdlXb1yefO6lt7MAa4DfapQfXCr+APGP+38fcC5g8TYAmZ1PCIVDFXPOmlc6be67C30HcFCKf1N7dv0tK1NPPbUhk8Y71+N24CWtsxNsKv4AitbUjgM+ALwbSOJtAHb+IJjisqLKd5xdWzL1mFNMuKi0/4+S3wq9+Hckslv++Er6icWN6QTQgndlt+c1rSOg4g80f9mHi4CFQAJ4u+/joWistHLuOacUT5xxgokU1gagUIu/qSu79cHXMs/e/nKqyXr7c/4EPFnXkOpxnU1yh4pfiNbUzgA+BBwDtAFNfR83RaWR8qNPnV0y9diF4WhssouMQ62Qij+TtZm1zdnVf2lMv/DYukwa793bn4FH6hpSnY7jSQ5S8QsA0Zpag1f8l+Fd6L0JaN3zeSVTj5tcduTChUVjp8w2oXBkhGMOmUIo/o6kbX1+U+aFP7ycWrGx3VYCEeBh4P66hlSL43iSw1T8shv/CKB5wIV46/4n8aaAMn2fF4qOLis/5rTjS6pmnhAqieZdgeZr8Vtr2dBm1/51XXrZ3a+m38paxuP93zwF/KWuIbX1AB9CRMUv/fPfAUzH2wF8Mt5Fe7bj7QvYTdlRJx5ZOm3ewkhs4kxjjBnRoAcp34q/J227Vm3NrvjT6tTzr2zLhoEo3ruyvwDL6hpSbW4TSj5R8csBRWtqRwEnAufhrf+fwNsI7PbDExkzORY98sQ5ReOPmBWKxqbk8kYgH4o/mbHJN1vtay9uzrz6p9WptYkUY4EwsAJvSqehriGV2f9HEdmbil8GLFpTGwaOBs7CuwZABtgG7HXESLhyXHlZ9fyZRROnz4qMmjDDhMJFI5t2/3K1+DuStu21pmzDso2ZhodfT6/vTjMKqAS68Mr+qbqG1Da3KSXfqfjloPhLQZyMd0JYGV4xNeGtC7QbU1QSKZs+f0bxYTWzIqOrZubCyWG5UvzWWrYn7OZXt2cblr6ZaXj2rcwWvOspj8Eb3b8O3A+sqmtIJV1mlcKh4pdDEq2pLQGOwzsXYD7ekSVZvI1AV3+vKZl63OSSqcfOKho7dVa4rHLSiIXtw2Xxp7M2vbHNrn/p7UzDw2vTDetabAcwGm9kD97O9KfxpnQ26OpXMtRU/DJkojW1RcAMvGmgk4CY/1AL0M4e+wQAQmWjSkuqaqoiY6dWRSrHTw6Xj5kcKomOGe6sI1X8mazNNHXZrZva7ab1LdlNf9uW3bx8c+btZIYQMBboPTFuDV7ZvwpsU9nLcFLxy7DwjwqagnduwMl45waAt2O4mT0OD+1rJDYGw1H8+yn53nVxyvDKPoQ3JbYcWAasqWtIdQxlFpH9UfHLiIjW1I4BZgLvxFsiOuQ/lMF7N9AJ7HPhsN6NQXjUpPGh0vLKUEm0IlQcrTRFJZWhotJKwkXRwRxEdDDFn8naTFeajs6kbe9M0dHWY9tbu237ji7b9ur27NY9Sr4Yb+qmHO+djsF75/MMsAp4va4hler3E4kMMxW/jDh/SmgSUIU3NXQM3slivc09oI3BbsKRUKRyfEW4YlxluHx0RahsVGWopLwyVBItJxSOGGNCoWw6Gs20jTWlo7YdlVnX/b/RX5VZSzZryWatzWYsmawl25Mm2dpj25u7bMe2hG3f2pFt39Bm27d22K59/Lb0V/KdwGvAamAj3rUQWjSFI7lAxS85YQAbgxDeWcS9tx68awoM+Ae4nK6qo82b88eYzsWDjBfGK/dioMT/M4RKXvKUil9yVp+NwWHAKGACMN6/jfHvg13vCgxeIafw5tBt31s5XeOOMW8cM9oklvrP7XsL4V2kJtTnNbBrPr4Z2OHftuEdtdSMSl7ykIpf8pa/rlAF3jRL75+9G4go3kg9jHeIaaSIVOlss/6wcab9DbzppN5b2r81+bcOvKmm3luPil0KiYpfRCRgQgd+ioiIFBIVv4hIwKj4RUQCRsUvIhIwKn4RkYBR8YuIBIyKX0QkYFT8IiIBo+IXEQkYFb+ISMCo+EVEAkbFLyISMP8fm8i8nY/zEjgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Declare a figure with a custom size\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# labels for the two classes\n",
    "labels = 'Positives', 'Negative'\n",
    "\n",
    "# Sizes for each slide\n",
    "sizes = [len(all_positive_tweets), len(all_negative_tweets)] \n",
    "\n",
    "# Declare pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.axis('equal')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at raw texts\n",
    "\n",
    "Before anything else, we can print a couple of tweets from the dataset to see how they look. Understanding the data is responsible for 80% of the success or failure in data science projects. We can use this time to observe aspects we'd like to consider when preprocessing our data.\n",
    "\n",
    "Below, you will print one random positive and one random negative tweet. We have added a color mark at the beginning of the string to further distinguish the two. (Warning: This is taken from a public dataset of real tweets and a very small portion has explicit content.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m@nechantya hi please do check our final design :) https://t.co/EXt098Yq1b\n",
      "\u001b[91mThere's totally no stomping at all :(\n"
     ]
    }
   ],
   "source": [
    "# print positive in greeen\n",
    "print('\\033[92m' + all_positive_tweets[random.randint(0,5000)])\n",
    "\n",
    "# print negative in red\n",
    "print('\\033[91m' + all_negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:\n",
    "\n",
    "* Tokenizing the string\n",
    "* Lowercasing\n",
    "* Removing stop words and punctuation\n",
    "* Stemming\n",
    "\n",
    "Let's see how we can do these to a given tweet. We will choose just one and see how this is transformed by each preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i\n"
     ]
    }
   ],
   "source": [
    "# Our selected sample. Complex enough to exemplify each step\n",
    "tweet = all_positive_tweets[2277]\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tigran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the stopwords from NLTK\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove hyperlinks,  Twitter marks and styles\n",
    "\n",
    "Since we have a Twitter dataset, we'd like to remove some substrings commonly used on the platform like the hashtag, retweet marks, and hyperlinks. We'll use the [re](https://docs.python.org/3/library/re.html) library to perform regular expression operations on our tweet. We'll define our search pattern and use the `sub()` method to remove matches by substituting with an empty character (i.e. `''`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mMy beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i\n",
      "\u001b[94m\n",
      "My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off… \n"
     ]
    }
   ],
   "source": [
    "print('\\033[92m' + tweet)\n",
    "print('\\033[94m')\n",
    "\n",
    "# remove old style retweet text \"RT\"\n",
    "#tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "# remove hyperlinks\n",
    "tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "\n",
    "# remove hashtags\n",
    "# only removing the hash # sign from the word\n",
    "tweet2 = re.sub(r'#', '', tweet2)\n",
    "\n",
    "print(tweet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the string\n",
    "\n",
    "To tokenize means to split the strings into individual words without blanks or tabs. In this same step, we will also convert each word in the string to lower case. The [tokenize](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual) module from NLTK allows us to do these easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mMy beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off… \n",
      "\u001b[94m\n",
      "\n",
      "Tokenized string:\n",
      "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '…']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m' + tweet2)\n",
    "print('\\033[94m')\n",
    "\n",
    "# instantiate tokenizer class\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "# tokenize tweets\n",
    "tweet_tokens = tokenizer.tokenize(tweet2)\n",
    "\n",
    "print()\n",
    "print('Tokenized string:')\n",
    "print(tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words and punctuations\n",
    "\n",
    "The next step is to remove stop words and punctuation. Stop words are words that don't add significant meaning to the text. You'll see the list provided by NLTK when you run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words\n",
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "Punctuation\n",
      "\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Import the english stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "print('Stop words\\n')\n",
    "print(stopwords_english)\n",
    "\n",
    "print('\\nPunctuation\\n')\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\n",
      "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '…']\n",
      "\u001b[94m\n",
      "removed stop words and punctuation:\n",
      "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '…']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweet_tokens)\n",
    "print('\\033[94m')\n",
    "\n",
    "tweets_clean = []\n",
    "\n",
    "for word in tweet_tokens: # Go through every word in your tokens list\n",
    "    if (word not in stopwords_english and  # remove stopwords\n",
    "        word not in string.punctuation):  # remove punctuation\n",
    "        tweets_clean.append(word)\n",
    "\n",
    "print('removed stop words and punctuation:')\n",
    "print(tweets_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "Stemming is the process of converting a word to its most general form, or stem. This helps in reducing the size of our vocabulary.\n",
    "\n",
    "Consider the words: \n",
    " * **learn**\n",
    " * **learn**ing\n",
    " * **learn**ed\n",
    " * **learn**t\n",
    " \n",
    "All these words are stemmed from its common root **learn**. However, in some cases, the stemming process produces words that are not correct spellings of the root word. For example, **happi** and **sunni**. That's because it chooses the most common stem for related words. For example, we can look at the set of words that comprises the different forms of happy:\n",
    "\n",
    " * **happ**y\n",
    " * **happi**ness\n",
    " * **happi**er\n",
    " \n",
    "We can see that the prefix **happi** is more commonly used. We cannot choose **happ** because it is the stem of unrelated words like **happen**.\n",
    " \n",
    "NLTK has different modules for stemming and we will be using the [PorterStemmer](https://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter) module which uses the [Porter Stemming Algorithm](https://tartarus.org/martin/PorterStemmer/). Let's see how we can use it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\n",
      "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '…']\n",
      "\u001b[94m\n",
      "stemmed words:\n",
      "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '…']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweets_clean)\n",
    "print('\\033[94m')\n",
    "\n",
    "# Instantiate stemming class\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# Create an empty list to store the stems\n",
    "tweets_stem = []\n",
    "\n",
    "for word in tweets_clean:\n",
    "    stem_word = stemmer.stem(word)  # stemming word\n",
    "    tweets_stem.append(stem_word)  # append to the list\n",
    "\n",
    "print('stemmed words:')\n",
    "print(tweets_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tigran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import  word_tokenize\n",
    "import nltk\n",
    "#nltk.download()\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "#from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "def text_prep(text):\n",
    "    \"\"\"Process string function.\n",
    "    Input:\n",
    "        text: a string containing a text\n",
    "    Output:\n",
    "        texts_clean: a list of words containing the processed text\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # remove stock market tickers like $GE\n",
    "    #tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # tokenize text\n",
    "    text_tokens = word_tokenize(text)\n",
    "\n",
    "    texts_clean = []\n",
    "    for word in text_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            texts_clean.append(stem_word)\n",
    "\n",
    "    return texts_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bag of Words Representation\n",
    "\n",
    "### Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s start by defining a corpus of a few different sample text messages.\n",
    "\n",
    "messages = [\"Hey hey hey lets go get lunch today :)\",\n",
    "           \"Did you go home?\",\n",
    "           \"Hey!!! I need a favor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did',\n",
       " 'favor',\n",
       " 'get',\n",
       " 'go',\n",
       " 'hey',\n",
       " 'home',\n",
       " 'lets',\n",
       " 'lunch',\n",
       " 'need',\n",
       " 'today',\n",
       " 'you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t3\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "# The sparse representation\n",
    "dtm = vect.transform(messages)\n",
    "repr(dtm)\n",
    "print(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    3     0     1      1     0      1    0\n",
       "1    1      0    0   1    0     1     0      0     0      0    1\n",
       "2    0      1    0   0    1     0     0      0     1      0    0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The representation in pandas dataframe\n",
    "import pandas as pd\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    1     0     1      0     0      0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you got another message soon after you created your document term matrix and want to add it in. \n",
    "new_message = ['Hey lets go get a drink tonight']\n",
    "new_dtm = vect.transform(new_message)\n",
    "pd.DataFrame(new_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def createDTM(messages):\n",
    "    vect = TfidfVectorizer()\n",
    "    dtm = vect.fit_transform(messages) # create DTM\n",
    "    \n",
    "    # create pandas dataframe of DTM\n",
    "    return pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>happen</th>\n",
       "      <th>happiness</th>\n",
       "      <th>hey</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379978</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.471078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471078</td>\n",
       "      <td>0.471078</td>\n",
       "      <td>0.335176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      favor       get    happen  happiness       hey      lets     lunch  \\\n",
       "0  0.000000  0.534046  0.000000   0.000000  0.379978  0.534046  0.534046   \n",
       "1  0.471078  0.000000  0.471078   0.471078  0.335176  0.000000  0.000000   \n",
       "\n",
       "       need  \n",
       "0  0.000000  \n",
       "1  0.471078  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\"Hey lets get lunch :)\",\n",
    "           \"Hey!!! I need happen happiness a favor\"]\n",
    "createDTM(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some arguments to consider\n",
    "# max_features = n : only considers the top n words orderd by term frequency\n",
    "# min_df = n : ignores words with a document frequency below n\n",
    "# max_df = n : ignores words with a document frequency above n\n",
    "# stop_words = [’ ‘] : ignores common words like 'the', 'that', 'which', etc. \n",
    "#You’ll need to define in a list what words you want to include. There are lists of \n",
    "#common stop words available online, the NLTK library also has a list of stop words built into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This  is  happy the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-24f4d018b5a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_prep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# implement tfidf function on the preprocessed text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer = text_prep)\n",
    "#X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-229a428b68f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidf_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_tfidfvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTD-IDF Vectorizer\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tfidfvect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_tokens = vectorizer.get_feature_names()\n",
    "df_tfidfvect = pd.DataFrame(data = X.toarray(), columns = tfidf_tokens)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example on pdf file\n",
    "#import textract\n",
    "#text = textract.process(\"C:\\\\Users\\\\Tigran\\\\Desktop\\\\AutoML\\\\notebooks\\\\monetary.pdf\")\n",
    "text1 = textract.process(\"C:\\\\Users\\\\Tigran\\\\Desktop\\\\AutoML\\\\data\\\\text\\\\multi.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'A Comparison of Event Models for Naive Bayes Text Classification\\r\\nAndrew McCallum\\xe2\\x80\\xa1\\xe2\\x80\\xa0\\r\\n\\r\\nKamal Nigam\\xe2\\x80\\xa0\\r\\n\\r\\nmccallum@justresearch.com\\r\\n\\xe2\\x80\\xa1\\r\\nJust Research\\r\\n4616 Henry Street\\r\\nPittsburgh, PA 15213\\r\\n\\r\\nknigam@cs.cmu.edu\\r\\n\\r\\nAbstract\\r\\nRecent approaches to text classification have used two\\r\\ndifferent first-order probabilistic models for classification, both of which make the naive Bayes assumption.\\r\\nSome use a multi-variate Bernoulli model, that is, a\\r\\nBayesian Network with no dependencies between words\\r\\nand binary word features (e.g. Larkey and Croft 1996;\\r\\nKoller and Sahami 1997). Others use a multinomial\\r\\nmodel, that is, a uni-gram language model with integer\\r\\nword counts (e.g. Lewis and Gale 1994; Mitchell 1997).\\r\\nThis paper aims to clarify the confusion by describing\\r\\nthe differences and details of these two models, and by\\r\\nempirically comparing their classification performance\\r\\non five text corpora. We find that the multi-variate\\r\\nBernoulli performs well with small vocabulary sizes,\\r\\nbut that the multinomial performs usually performs\\r\\neven better at larger vocabulary sizes\\xe2\\x80\\x94providing on\\r\\naverage a 27% reduction in error over the multi-variate\\r\\nBernoulli model at any vocabulary size.\\r\\n\\r\\nIntroduction\\r\\nSimple Bayesian classifiers have been gaining popularity\\r\\nlately, and have been found to perform surprisingly well\\r\\n(Friedman 1997; Friedman et al. 1997; Sahami 1996;\\r\\nLangley et al. 1992). These probabilistic approaches\\r\\nmake strong assumptions about how the data is generated, and posit a probabilistic model that embodies\\r\\nthese assumptions; then they use a collection of labeled\\r\\ntraining examples to estimate the parameters of the\\r\\ngenerative model. Classification on new examples is\\r\\nperformed with Bayes\\xe2\\x80\\x99 rule by selecting the class that\\r\\nis most likely to have generated the example.\\r\\nThe naive Bayes classifier is the simplest of these\\r\\nmodels, in that it assumes that all attributes of the\\r\\nexamples are independent of each other given the context of the class. This is the so-called \\xe2\\x80\\x9cnaive Bayes\\r\\nassumption.\\xe2\\x80\\x9d While this assumption is clearly false\\r\\nin most real-world tasks, naive Bayes often performs\\r\\nclassification very well. This paradox is explained by\\r\\nthe fact that classification estimation is only a function\\r\\nof the sign (in binary cases) of the function estimation; the function approximation can still be poor while\\r\\nclassification accuracy remains high (Friedman 1997;\\r\\nDomingos and Pazzani 1997). Because of the independence assumption, the parameters for each attribute\\r\\ncan be learned separately, and this greatly simplifies\\r\\n\\r\\n\\xe2\\x80\\xa0\\r\\n\\r\\nSchool of Computer Science\\r\\nCarnegie Mellon University\\r\\nPittsburgh, PA 15213\\r\\n\\r\\nlearning, especially when the number of attributes is\\r\\nlarge.\\r\\nDocument classification is just such a domain with\\r\\na large number of attributes. The attributes of the\\r\\nexamples to be classified are words, and the number\\r\\nof different words can be quite large indeed. While\\r\\nsome simple document classification tasks can be accurately performed with vocabulary sizes less than one\\r\\nhundred, many complex tasks on real-world data from\\r\\nthe Web, UseNet and newswire articles do best with vocabulary sizes in the thousands. Naive Bayes has been\\r\\nsuccessfully applied to document classification in many\\r\\nresearch efforts (see references below).\\r\\nDespite its popularity, there has been some confusion in the document classification community about\\r\\nthe \\xe2\\x80\\x9cnaive Bayes\\xe2\\x80\\x9d classifier because there are two different generative models in common use, both of which\\r\\nmake the \\xe2\\x80\\x9cnaive Bayes assumption.\\xe2\\x80\\x9d Both are called\\r\\n\\xe2\\x80\\x9cnaive Bayes\\xe2\\x80\\x9d by their practitioners.\\r\\nOne model specifies that a document is represented\\r\\nby a vector of binary attributes indicating which words\\r\\noccur and do not occur in the document. The number\\r\\nof times a word occurs in a document is not captured.\\r\\nWhen calculating the probability of a document, one\\r\\nmultiplies the probability of all the attribute values,\\r\\nincluding the probability of non-occurrence for words\\r\\nthat do not occur in the document. Here we can understand the document to be the \\xe2\\x80\\x9cevent,\\xe2\\x80\\x9d and the absence or presence of words to be attributes of the event.\\r\\nThis describes a distribution based on a multi-variate\\r\\nBernoulli event model. This approach is more traditional in the field of Bayesian networks, and is appropriate for tasks that have a fixed number of attributes.\\r\\nThe approach has been used for text classification by\\r\\nnumerous people (Robertson and Sparck-Jones 1976;\\r\\nLewis 1992; Kalt and Croft 1996; Larkey and Croft\\r\\n1996; Koller and Sahami 1997; Sahami 1996).\\r\\nThe second model specifies that a document is represented by the set of word occurrences from the document. As above, the order of the words is lost, however, the number of occurrences of each word in the\\r\\ndocument is captured. When calculating the probability of a document, one multiplies the probability of\\r\\nthe words that occur. Here we can understand the individual word occurrences to be the \\xe2\\x80\\x9cevents\\xe2\\x80\\x9d and the\\r\\ndocument to be the collection of word events. We call\\r\\n\\r\\n\\x0cthis the multinomial event model. This approach is\\r\\nmore traditional in statistical language modeling for\\r\\nspeech recognition, where it would be called a \\xe2\\x80\\x9cunigram language model.\\xe2\\x80\\x9d This approach has also been\\r\\nused for text classification by numerous people (Lewis\\r\\nand Gale 1994; Kalt and Croft 1996; Joachims 1997;\\r\\nGuthrie and Walker 1994; Li and Yamanishi 1997;\\r\\nMitchell 1997; Nigam et al. 1998; McCallum et al.\\r\\n1998).\\r\\nThis paper aims to clarify the confusion between\\r\\nthese two approaches by explaining both models in\\r\\ndetail. We present an extensive empirical comparison on five corpora, including Web pages, UseNet articles and Reuters newswire articles. Our results indicate that the multi-variate Bernoulli model sometimes\\r\\nperforms better than the multinomial at small vocabulary sizes. However, the multinomial usually outperforms the multi-variate Bernoulli at large vocabulary sizes, and almost always beats the multi-variate\\r\\nBernoulli when vocabulary size is chosen optimally for\\r\\nboth. While sometimes the difference in performance is\\r\\nnot great, on average across data sets, the multinomial\\r\\nprovides a 27% reduction in error over the multi-variate\\r\\nBernoulli.\\r\\n\\r\\nProbabilistic Framework of Naive Bayes\\r\\nThis section presents the generative model for both\\r\\ncases of the naive Bayes classifier. First we explain\\r\\nthe mechanisms they have in common, then, where the\\r\\nevent models diverge, the assumptions and formulations\\r\\nof each are presented.\\r\\nConsider the task of text classification in a Bayesian\\r\\nlearning framework. This approach assumes that the\\r\\ntext data was generated by a parametric model, and\\r\\nuses training data to calculate Bayes-optimal estimates\\r\\nof the model parameters. Then, equipped with these\\r\\nestimates, it classifies new test documents using Bayes\\xe2\\x80\\x99\\r\\nrule to turn the generative model around and calculate\\r\\nthe posterior probability that a class would have generated the test document in question. Classification then\\r\\nbecomes a simple matter of selecting the most probable\\r\\nclass.\\r\\nBoth scenarios assume that text documents are generated by a mixture model parameterized by \\xce\\xb8. The\\r\\nmixture model consists of mixture components cj \\xe2\\x88\\x88\\r\\nC = {c1 , ..., c|C|}. Each component is parameterized by\\r\\na disjoint subset of \\xce\\xb8. Thus a document, di, is created\\r\\nby (1) selecting a component according to the priors,\\r\\nP(cj |\\xce\\xb8), then (2) having the mixture component generate a document according to its own parameters, with\\r\\ndistribution P(di |cj ; \\xce\\xb8). We can characterize the likelihood of a document with a sum of total probability\\r\\nover all mixture components:\\r\\nP(di |\\xce\\xb8) =\\r\\n\\r\\n|C|\\r\\nX\\r\\n\\r\\nand mixture model components, and thus use cj to indicate both the jth mixture component and the jth\\r\\nclass.1 In this setting, (supervised learning from labeled training examples), the typically \\xe2\\x80\\x9chidden\\xe2\\x80\\x9d indicator variables for a mixture model are provided as these\\r\\nclass labels.\\r\\n\\r\\nMulti-variate Bernoulli Model\\r\\nIn the multi-variate Bernoulli event model, a document\\r\\nis a binary vector over the space of words. Given\\r\\na vocabulary V , each dimension of the space t, t \\xe2\\x88\\x88\\r\\n{1, . . . , |V |}, corresponds to word wt from the vocabulary. Dimension t of the vector for document di is written Bit , and is either 0 or 1, indicating whether word\\r\\nwt occurs at least once in the document. With such\\r\\na document representation, we make the naive Bayes\\r\\nassumption: that the probability of each word occurring in a document is independent of the occurrence of\\r\\nother words in a document. Then, the probability of a\\r\\ndocument given its class from Equation 1 is simply the\\r\\nproduct of the probability of the attribute values over\\r\\nall word attributes:\\r\\n\\r\\nP(di |cj ; \\xce\\xb8) =\\r\\n\\r\\n|V |\\r\\nY\\r\\n\\r\\n(Bit P(wt |cj ; \\xce\\xb8) +\\r\\n(1 \\xe2\\x88\\x92 Bit )(1 \\xe2\\x88\\x92 P(wt |cj ; \\xce\\xb8))).\\r\\n\\r\\nThus given a generating component, a document can\\r\\nbe seen as a collection of multiple independent Bernoulli\\r\\nexperiments, one for each word in the vocabulary, with\\r\\nthe probabilities for each of these word events defined\\r\\nby each component, P(wt |cj ; \\xce\\xb8). This is equivalent to\\r\\nviewing the distribution over documents as being described by a Bayesian network, where the absence or\\r\\npresence of each word is dependent only on the class of\\r\\nthe document.\\r\\nGiven a set of labeled training documents, D =\\r\\n{d1 , . . . , d|D|}, learning the parameters of a probabilistic classification model corresponds to estimating each\\r\\nof these class-conditional word probabilities. The parameters of a mixture component are written \\xce\\xb8wt |cj =\\r\\nP(wt |cj ; \\xce\\xb8), where 0 \\xe2\\x89\\xa4 \\xce\\xb8wt |cj \\xe2\\x89\\xa4 1. We can calculate Bayes-optimal estimates for these probabilities by\\r\\nstraightforward counting of events, supplemented by a\\r\\nprior (Vapnik 1982). We use the Laplacean prior, priming each word\\xe2\\x80\\x99s count with a count of one to avoid probabilities of zero or one. Define P(cj |di) \\xe2\\x88\\x88 {0, 1} as given\\r\\nby the document\\xe2\\x80\\x99s class label. Then, we estimate the\\r\\nprobability of word wt in class cj with:\\r\\n\\r\\n\\xce\\xb8\\xcc\\x82wt |cj = P(wt |cj ; \\xce\\xb8) =\\r\\nP(cj |\\xce\\xb8)P(di |cj ; \\xce\\xb8).\\r\\n\\r\\n(1)\\r\\n\\r\\nj=1\\r\\n\\r\\nEach document has a class label. We assume that\\r\\nthere is a one-to-one correspondence between classes\\r\\n\\r\\n(2)\\r\\n\\r\\nt=1\\r\\n\\r\\nP|D|\\r\\n\\r\\ni=1 Bit P(cj |di )\\r\\n.\\r\\nP|D|\\r\\n2 + i=1 P(cj |di)\\r\\n\\r\\n1+\\r\\n\\r\\n(3)\\r\\n\\r\\n1\\r\\nIn a more general setting, this one-to-one correspondence can be avoided (Li and Yamanishi 1997; Nigam et al.\\r\\n1998).\\r\\n\\r\\n\\x0cThe class prior parameters, \\xce\\xb8cj , are set by the maximum likelihood estimate:\\r\\nP|D|\\r\\n\\xce\\xb8\\xcc\\x82cj = P(cj |\\xce\\xb8\\xcc\\x82) =\\r\\n\\r\\ni=1 P(cj |di )\\r\\n\\r\\n|D|\\r\\n\\r\\n.\\r\\n\\r\\n(4)\\r\\n\\r\\nNote that this model does not capture the number of\\r\\ntimes each word occurs, and that it explicitly includes\\r\\nthe non-occurrence probability of words that do not appear in the document.\\r\\n\\r\\nMultinomial Model\\r\\nIn contrast to the multi-variate Bernoulli event model,\\r\\nthe multinomial model captures word frequency information in documents. Consider, for example, the occurrence of numbers in the Reuters newswire articles;\\r\\nour tokenization maps all strings of digits to a common token. Since every news article is dated, and thus\\r\\nhas a number, the number token in the multi-variate\\r\\nBernoulli event model is uninformative. However, news\\r\\narticles about earnings tend to have a lot of numbers\\r\\ncompared to general news articles. Thus, capturing frequency information of this token can help classification.\\r\\nIn the multinomial model, a document is an ordered\\r\\nsequence of word events, drawn from the same vocabulary V . We assume that the lengths of documents\\r\\nare independent of class.2 We again make a similar\\r\\nnaive Bayes assumption: that the probability of each\\r\\nword event in a document is independent of the word\\xe2\\x80\\x99s\\r\\ncontext and position in the document. Thus, each document di is drawn from a multinomial distribution of\\r\\nwords with as many independent trials as the length\\r\\nof di. This yields the familiar \\xe2\\x80\\x9cbag of words\\xe2\\x80\\x9d representation for documents. Define Nit to be the count\\r\\nof the number of times word wt occurs in document di.\\r\\nThen, the probability of a document given its class from\\r\\nEquation 1 is simply the multinomial distribution:\\r\\n\\r\\nP(di|cj ; \\xce\\xb8) = P(|di|)|di|!\\r\\n\\r\\n|V |\\r\\nY\\r\\nP(wt |cj ; \\xce\\xb8)Nit\\r\\nt=1\\r\\n\\r\\nNit !\\r\\n\\r\\n.\\r\\n\\r\\n(5)\\r\\n\\r\\nThe parameters of the generative component for\\r\\neach class are the probabilities for each word, written\\r\\nP \\xce\\xb8wt |cj = P(wt |cj ; \\xce\\xb8), where 0 \\xe2\\x89\\xa4 \\xce\\xb8wt |cj \\xe2\\x89\\xa4 1 and\\r\\nt \\xce\\xb8wt |cj = 1.\\r\\nAgain, we can calculate Bayes-optimal estimates for\\r\\nthese parameters from a set of labeled training data.\\r\\nHere, the estimate of the probability of word wt in class\\r\\ncj is:\\r\\n2\\r\\nMany previous formalizations of the multinomial model\\r\\nhave omitted document length. Including document length\\r\\nis necessary because document length specifies the number\\r\\nof draws from the multinomial. Our the assumption that\\r\\ndocument length contains no class information is a simplification only. In practice document length may be class dependent, and a more general formalization should capture\\r\\nthis.\\r\\n\\r\\nP|D|\\r\\n1 + i=1 Nit P(cj |di)\\r\\n\\xce\\xb8\\xcc\\x82wt |cj = P(wt |cj ; \\xce\\xb8\\xcc\\x82j ) =\\r\\n.\\r\\nP|V | P|D|\\r\\n|V | + s=1 i=1 Nis P(cj |di)\\r\\n(6)\\r\\nThe class prior parameters are calculated as before\\r\\naccording to Equation 4.\\r\\n\\r\\nClassification\\r\\nGiven estimates of these parameters calculated from the\\r\\ntraining documents, classification can be performed on\\r\\ntest documents by calculating the posterior probability\\r\\nof each class given the evidence of the test document,\\r\\nand selecting the class with the highest probability. We\\r\\nformulate this by applying Bayes\\xe2\\x80\\x99 rule:\\r\\nP(cj |di; \\xce\\xb8\\xcc\\x82)\\r\\n\\r\\n=\\r\\n\\r\\nP(cj |\\xce\\xb8\\xcc\\x82)P(di |cj ; \\xce\\xb8\\xcc\\x82j )\\r\\nP(di |\\xce\\xb8\\xcc\\x82)\\r\\n\\r\\n.\\r\\n\\r\\n(7)\\r\\n\\r\\nThe right hand side may be expanded by first substituting using Equations 1 and 4. Then the expansion\\r\\nof individual terms for this equation are dependent on\\r\\nthe event model used. Use Equations 2 and 3 for the\\r\\nmulti-variate Bernoulli event model. Use Equations 5\\r\\nand 6 for the multinomial\\r\\n\\r\\nFeature Selection\\r\\nWhen reducing the vocabulary size, feature selection\\r\\nis done by selecting words that have highest average\\r\\nmutual information with the class variable (Cover and\\r\\nThomas 1991). This method works well with text and\\r\\nhas been used often (Yang and Pederson 1997; Joachims\\r\\n1997; Craven et al. 1998).\\r\\nIn all previous work of which we are aware, this is\\r\\ndone by calculating the average mutual information between the (1) class of a document and (2) the absence\\r\\nor presence of a word in the document, i.e. using a\\r\\ndocument event model, the multi-variate Bernoulli. We\\r\\nwrite C for a random variable over all classes, and write\\r\\nWt for a random variable over the absence or presence\\r\\nof word wt in a document, where Wt takes on values\\r\\nft \\xe2\\x88\\x88 {0, 1}, and ft = 0 indicates the absence of wt ,\\r\\nand ft = 1 indicates the presence of wt . Average mutual information is the difference between the entropy\\r\\nof the class variable, H(C), and the entropy of the class\\r\\nvariable conditioned on the absence or presence of the\\r\\nword, H(C|Wt ) (Cover and Thomas 1991):\\r\\nI(C; Wt )\\r\\n\\r\\n= H(C) \\xe2\\x88\\x92 H(C|Wt )\\r\\nX\\r\\n= \\xe2\\x88\\x92\\r\\nP(c) log(P(c))\\r\\nc\\xe2\\x88\\x88C\\r\\n\\r\\nX\\r\\n\\r\\n+\\r\\n\\r\\nP(ft )\\r\\n\\r\\nft \\xe2\\x88\\x88{0,1}\\r\\n\\r\\n=\\r\\n\\r\\nX\\r\\n\\r\\nX\\r\\n\\r\\nc\\xe2\\x88\\x88C ft \\xe2\\x88\\x88{0,1}\\r\\n\\r\\nX\\r\\n\\r\\n(8)\\r\\n\\r\\nP(c|ft ) log(P(c|ft ))\\r\\n\\r\\nc\\xe2\\x88\\x88C\\r\\n\\r\\nP(c, ft ) log\\r\\n\\r\\n\\x12\\r\\n\\r\\nP(c, ft )\\r\\nP(c)P(ft )\\r\\n\\r\\n\\x13\\r\\n,\\r\\n\\r\\n\\x0cwhere P(c), P(ft ) and P(c, ft ) are calculated by sums\\r\\nover all documents\\xe2\\x80\\x94that is P(c) is the number of documents with class label c divided by the total number of\\r\\ndocuments; P(ft ) is the number of documents containing one or more occurrences of word wt divided by the\\r\\ntotal number of documents; and P(c, ft ) is the number\\r\\nof documents with class label c that also contain word\\r\\nwt , divided by the total number of documents.\\r\\nWe experimented with this method, as well as an\\r\\nevent model that corresponds to the multinomial: calculating the mutual information between (1) the class of\\r\\nthe document from which a word occurrence is drawn,\\r\\nand (2) a random variable over all word occurrences.\\r\\nHere the word occurrences are the events. This calculation also uses Equation 8, but calculates the values\\r\\nof the terms by sums over word occurrences instead of\\r\\nover documents\\xe2\\x80\\x94that is P(c) is the number of word\\r\\noccurrences appearing in documents with class label c\\r\\ndivided by the total number of word occurrences; P(ft )\\r\\nis the number of occurrences of word wt divided by the\\r\\ntotal number of word occurrences; and P(c, ft ) is the\\r\\nnumber of word occurrences of word wt that also appear in documents with class label c, divided by the\\r\\ntotal number of word occurrences.\\r\\nOur preliminary experiments comparing these two\\r\\nfeature selection methods on the Newsgroups data set\\r\\nwith the multinomial event model showed little difference in classification accuracy. The results reported in\\r\\nthis paper use the feature selection event model that\\r\\ncorresponds to the event model used for classification.\\r\\n\\r\\nExperimental Results\\r\\nThis section provides empirical evidence that the multinomial event model usually performs better than the\\r\\nmulti-variate Bernoulli. The results are based on five\\r\\ndifferent data sets.3\\r\\n\\r\\nData Sets and Protocol\\r\\nThe web pages pointed to by the Yahoo! \\xe2\\x80\\x98Science\\xe2\\x80\\x99 hierarchy were gathered in July 1997. The web pages are\\r\\ndivided into 95 disjoint classes containing 13589 pages\\r\\nas the result of coalescing classes of hierarchy-depth\\r\\ngreater than two, and removing those classes with fewer\\r\\nthan 40 documents. After tokenizing as above and removing stopwords and words that occur only once, the\\r\\ncorpus has a vocabulary size of 44383 (McCallum et al.\\r\\n1998).\\r\\nThe Industry Sector hierarchy, made available by Market Guide Inc. (www.marketguide.com) consists of\\r\\ncompany web pages classified in a hierarchy of industry\\r\\nsectors (McCallum et al. 1998). There are 6440 web\\r\\npages partitioned into the 71 classes that are two levels\\r\\ndeep in the hierarchy. In tokenizing the data we do not\\r\\nstem. After removing tokens that occur only once or\\r\\n3\\r\\nThese data sets are all available on the Internet.\\r\\nSee http://www.cs.cmu.edu/\\xe2\\x88\\xbctextlearning and\\r\\nhttp://www.research.att.com/\\xe2\\x88\\xbclewis.\\r\\n\\r\\nare on a stoplist, the corpus has a vocabulary of size\\r\\n29964.\\r\\nThe Newsgroups data set, collected by Ken Lang,\\r\\ncontains about 20,000 articles evenly divided among\\r\\n20 UseNet discussion groups (Joachims 1997). Many\\r\\nof the categories fall into confusable clusters; for example, five of them are comp.* discussion groups, and\\r\\nthree of them discuss religion. When tokenizing this\\r\\ndata, we skip the UseNet headers (thereby discarding\\r\\nthe subject line); tokens are formed from contiguous alphabetic characters with no stemming. The resulting\\r\\nvocabulary, after removing words that occur only once\\r\\nor on a stoplist, has 42191 words.\\r\\nThe WebKB data set (Craven et al. 1998) contains\\r\\nweb pages gathered from university computer science\\r\\ndepartments. The pages are divided into seven categories: student, faculty, staff, course, project, department\\r\\nand other. In this paper, we use the four most populous\\r\\nentity-representing categories: student, faculty, course\\r\\nand project, all together containing 4199 pages. We\\r\\ndid not use stemming or a stoplist; we found that using a stoplist actually hurt performance because, for\\r\\nexample, \\xe2\\x80\\x9cmy\\xe2\\x80\\x9d is the fourth-ranked word by mutual\\r\\ninformation, and is an excellent indicator of a student\\r\\nhomepage. The resulting vocabulary has 23830 words.\\r\\nThe \\xe2\\x80\\x98ModApte\\xe2\\x80\\x99 train/test split of the Reuters 21578\\r\\nDistribution 1.0 data set consists of 12902 Reuters\\r\\nnewswire articles in 135 overlapping topic categories.\\r\\nFollowing several other studies (Joachims 1998; Liere\\r\\nand Tadepalli 1997) we build binary classifiers for each\\r\\nof the 10 most populous classes. We ignore words on\\r\\na stoplist, but do not use stemming. The resulting vocabulary has 19371 words.\\r\\nFor all data sets except Reuters, naive Bayes is performed with randomly selected train-test splits. The\\r\\nIndustry Sector and Newsgroups data sets use five trials with 20% of the data held out for testing; Yahoo\\r\\nuses five trials with a 30% test data, and WebKB uses\\r\\nten trials with a 30% test data. Results are reported\\r\\nas average classification accuracy across trials. In all\\r\\nexperiments with multiple trials graphs show small error bars twice the width of the standard error; however\\r\\nthey are often hard to see since they are often quite narrow. For Reuters, results on the Mod-Apte test set are\\r\\nshown as precision-recall breakeven points, a standard\\r\\ninformation retrieval measure for binary classification.\\r\\nRecall and Precision are defined as:\\r\\n# of correct positive predictions\\r\\n(9)\\r\\n# of positive examples\\r\\n# of correct positive predictions\\r\\nPrecision =\\r\\n(10)\\r\\n# of positive predictions\\r\\nThe precision-recall breakeven point is the value at\\r\\nwhich precision and recall are equal (Joachims 1998).\\r\\nRecall =\\r\\n\\r\\nResults\\r\\nFigure 1 shows results on the Yahoo data set. The\\r\\nmultinomial event model reaches a maximum of 54%\\r\\n\\r\\n\\x0cYahoo Science\\r\\n\\r\\nNewsgroups\\r\\n\\r\\n100\\r\\n\\r\\n100\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n80\\r\\nClassification Accuracy\\r\\n\\r\\nClassification Accuracy\\r\\n\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\nFigure 1: A comparison of event models for different\\r\\nvocabulary sizes on the Yahoo data set. Note that the\\r\\nmulti-variate Bernoulli performs best with a small vocabulary and that the multinomial performs best with\\r\\na larger vocabulary. The multinomial achieves higher\\r\\naccuracy overall.\\r\\n\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\nFigure 3: A comparison of event models for different vocabulary sizes on the Newsgroups data set. Here, both\\r\\ndata sets perform best at the full vocabulary, but multinomial achieves higher accuracy.\\r\\nWebKB 4\\r\\n100\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\nIndustry Sector 71\\r\\n100\\r\\n\\r\\n80\\r\\nClassification Accuracy\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\nClassification Accuracy\\r\\n\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\nFigure 2: A comparison of event models for different\\r\\nvocabulary sizes on the Industry Sector data set. Note\\r\\nthe same trends as seen in the previous figure.\\r\\naccuracy at a vocabulary size of 1000 words. The multivariate Bernoulli event model reaches a maximum of\\r\\n41% accuracy with only 200 words. Note that the multivariate Bernoulli shows its best results at a smaller vocabulary than the multinomial, and that the multinomial has best performance at a larger vocabulary size.\\r\\nThe same pattern is seen in the Industry Sector data set,\\r\\ndisplayed in Figure 2. Here, multinomial has the highest accuracy of 74% at 20000 words, and multi-variate\\r\\nBernoulli is best with 46% accuracy at 1000 words.4\\r\\nFigure 3 shows results for the Newsgroups data set.\\r\\nHere, both event models do best at the maximum vocabulary sizes. Multinomial achieves 85% accuracy and\\r\\n4\\r\\nAccuracies are higher here than reported in (McCallum\\r\\net al. 1998) because here more training data was provided\\r\\nto this classifier (70% of the data used for training here,\\r\\nversus only 50% in the other work).\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\nFigure 4: A comparison of event models for different\\r\\nvocabulary sizes on the WebKB data set. Here the two\\r\\nevent models achieve nearly equivalent accuracies, but\\r\\nthe multi-variate Bernoulli achieves this with a smaller\\r\\nvocabulary.\\r\\nmulti-variate Bernoulli achieves 74% accuracy. Previous results in this domain are consistent in that best\\r\\nresults were with the full vocabulary (Joachims 1997;\\r\\nNigam et al. 1998). For the WebKB data, shown in Figure 4, the multi-variate Bernoulli has marginally higher\\r\\naccuracy than the multinomial, 87% accuracy at 100\\r\\nwords versus 86% accuracy at 5000 words. In ongoing\\r\\nwork we are exploring the reasons that this data set\\r\\nshows results different from the others.\\r\\nFigures 5 and 6 show breakeven point results for the\\r\\nten Reuters categories. Again, the trends are distinctive. The multi-variate Bernoulli achieves a slightly\\r\\nhigher breakeven point in one case, but on average\\r\\nacross categories, its best performance is 4.8 percentage points less than the multinomial. The multi-variate\\r\\nBernoulli has a rapid decrease in performance as the\\r\\nvocabulary size grows, where the multinomial performance is more even across vocabulary size. Results by\\r\\n\\r\\n\\x0cinterest\\r\\n100\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\nship\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n100\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\nFigure 5: Two of the classification tasks from Reuters.\\r\\nMultinomial event models do an average of 4.8% points\\r\\nbetter. This domain tends to require smaller vocabularies for best performance. See Figure 6 for the remaining\\r\\nReuters results.\\r\\nJoachims (1998) found performance was highest in this\\r\\ndomain with the full vocabulary (no feature selection).\\r\\nHowever, in contrast to our results, this work uses the\\r\\nmulti-variate Bernoulli event model for feature selection\\r\\nand the multinomial for classification. In future work\\r\\nwe plan to investigate these feature selection methods\\r\\nmore closely because we note that our results are consistently higher than those found in that work.\\r\\n\\r\\nDiscussion\\r\\nFor easy classification tasks, a small vocabulary is sufficient for high performance. The Reuters categorization\\r\\ntasks are examples of these\\xe2\\x80\\x94it is well-known that in\\r\\nseveral of the categories, high accuracy can be obtained\\r\\nwith only a handful of words, sometimes even the single\\r\\nword that is the title of the category (Joachims 1998).\\r\\nOur results are consistent with this, in that best performance is often achieved with small vocabulary sizes.\\r\\nMany real-world classification tasks do not share this\\r\\nattribute (i.e. that all documents in a category are\\r\\nabout a single narrow subject with limited vocabulary),\\r\\nbut instead, a category consists of diverse subject matters with overlapping vocabularies. In such tasks large\\r\\nvocabularies are required for adequate classification ac-\\r\\n\\r\\ncuracy. Since our results show that the multi-variate\\r\\nBernoulli handles large vocabularies poorly, the multinomial event model is more appropriate for these challenging classification tasks.\\r\\nIt would be incorrect to argue that multi-variate\\r\\nBernoulli has the advantage of counting evidence for\\r\\nwords that do not occur. Multinomials implicitly encode this information in the probability distributions\\r\\nof words for each class. For example, if the word \\xe2\\x80\\x9cprofessor\\xe2\\x80\\x9d is the most likely word for faculty home pages, it\\r\\nwill have a large probability for the faculty class, and all\\r\\nother words will be less probable. If the word \\xe2\\x80\\x9cprofessor\\xe2\\x80\\x9d does not then occur in a document, that document\\r\\nwill be less likely to be a faculty document, because the\\r\\nwords in that document will be lower frequency in the\\r\\nfaculty class and higher frequency in others.\\r\\nAnother point to consider is that the multinomial\\r\\nevent model should be a more accurate classifier for\\r\\ndata sets that have a large variance in document length.\\r\\nThe multinomial event model naturally handles documents of varying length by incorporating the evidence\\r\\nof each appearing word. The multi-variate Bernoulli\\r\\nmodel is a somewhat poor fit for data with varying\\r\\nlength, in that it is more likely for a word to occur in a\\r\\nlong document regardless of the class. Thus, the variance of the classification should be large for documents\\r\\nof varying lengths. Testing this hypothesis is a topic\\r\\nof future work. Lewis also discusses difficulties with\\r\\ndocument-length in the multi-variate Bernoulli model.\\r\\nWhen adding non-text features to the classifier, (such\\r\\nas whether or not an email message has more than\\r\\none recipient), such features can be included exactly\\r\\nas the word features are when using the multi-variate\\r\\nBernoulli model (Sahami et al. 1998). However, in\\r\\nthe multinomial model more care must be taken. The\\r\\nnon-text features should not be added to the vocabulary because then the event spaces for the different features would compete for the same probability mass even\\r\\nthough they are not mutually exclusive. Non-text features could be added as additional Bernoulli variables\\r\\nto be included in conjunction with the multinomial over\\r\\nwords. This approach could also allow for a weighting\\r\\nfactor between the word features and the other features.\\r\\nIt is also more clear in the multi-variate Bernoulli\\r\\nmodel how to relax the independence assumption\\r\\nby adding a limited number of dependencies to the\\r\\nBayesian network (Sahami 1996; Friedman et al. 1997).\\r\\n\\r\\nRelated Work\\r\\nKalt and Croft (1996) previously compared the multinomial model to the \\xe2\\x80\\x9cbinary independence model,\\xe2\\x80\\x9d the\\r\\ninformation retrieval terminology for our multi-variate\\r\\nBernoulli model. Their theoretical analysis of the multinomial does not properly address document length assumptions. Their experiments use a single data set\\r\\nwith extremely small vocabularies. Also, by normalizing document length, their event model is no longer\\r\\nstrictly a multinomial.\\r\\n\\r\\n\\x0cLewis (1998) discusses the history of naive Bayes\\r\\nin information retrieval, and presents a theoretical\\r\\ncomparison of the multinomial and the multi-variate\\r\\nBernoulli (again called the binary independence model).\\r\\n\\r\\nConclusions\\r\\nThis paper has compared the theory and practice of\\r\\ntwo different first-order probabilistic classifiers, both of\\r\\nwhich make the \\xe2\\x80\\x9cnaive Bayes assumption.\\xe2\\x80\\x9d The multinomial model is found to be almost uniformly better\\r\\nthan the multi-variate Bernoulli model. In empirical\\r\\nresults on five real-world corpora we find that the multinomial model reduces error by an average of 27%, and\\r\\nsometimes by more than 50%.\\r\\nIn future work we will investigate the role of document length in classification, looking for correspondence between variations in document length and the\\r\\ncomparative performance of multi-variate Bernoulli and\\r\\nmultinomial. We will also investigate event models that\\r\\nnormalize the word occurrence counts in a document by\\r\\ndocument length, and work with more complex models\\r\\nthat model document length explicitly on a per-class\\r\\nbasis.\\r\\nWe also plan experiments with varying amounts of\\r\\ntraining data because we hypothesize that that optimal\\r\\nvocabulary size may change with the size of the training\\r\\nset.\\r\\n\\r\\nAcknowledgments\\r\\nWe thank Doug Baker for help formatting the Reuters\\r\\ndata set. We thank Market Guide, Inc. for permission\\r\\nto use their Industry Sector hierarchy, and Mark Craven\\r\\nfor gathering its data from the Web. We thank Yahoo! for permission to use their data. We thank Tom\\r\\nMitchell for helpful and enlightening discussions. This\\r\\nresearch was supported in part by the Darpa HPKB\\r\\nprogram under contract F30602-97-1-0215.\\r\\n\\r\\nReferences\\r\\nThomas M. Cover and Joy A. Thomas. Elements of Information Theory. John Wiley, 1991.\\r\\nM. Craven, D. DiPasquo, D. Freitag, A. McCallum,\\r\\nT. Mitchell, K. Nigam, and S. Slattery. Learning to extract symbolic knowledge from the World Wide Web. In\\r\\nAAAI-98, 1998.\\r\\nP. Domingos and M. Pazzani. On the optimality of the\\r\\nsimple Bayesian classifier under zero-one loss. Machine\\r\\nLearning, 29:103\\xe2\\x80\\x93130, 1997.\\r\\nNir Friedman, Dan Geiger, and Moises Goldszmidt.\\r\\nBayesian network classifiers. Machine Learning, 29:131\\xe2\\x80\\x93\\r\\n163, 1997.\\r\\nJerome H. Friedman. On bias, variance, 0/1 - loss, and\\r\\nthe curse-of-dimensionality. Data Mining and Knowledge\\r\\nDiscovery, 1:55\\xe2\\x80\\x9377, 1997.\\r\\nLouise Guthrie and Elbert Walker. Document classification by machine: Theory and practice. In Proceedings of\\r\\nCOLING-94, 1994.\\r\\n\\r\\nThorsten Joachims. A probabilistic analysis of the Rocchio\\r\\nalgorithm with TFIDF for text categorization. In ICML97, 1997.\\r\\nThorsten Joachims. Text categorization with Support Vector Machines: Learning with many relevant features. In\\r\\nECML-98, 1998.\\r\\nT. Kalt and W. B. Croft. A new probabilistic model of\\r\\ntext\\r\\nclassification and retrieval. Technical Report IR-78, University of\\r\\nMassachusetts Center for Intelligent Information Retrieval,\\r\\n1996. http://ciir.cs.umass.edu/publications/index.shtml.\\r\\nDaphne Koller and Mehran Sahami. Hierarchically classifying documents using very few words. In Proceedings\\r\\nof the Fourteenth International Conference on Machine\\r\\nLearning, 1997.\\r\\nPat Langley, Wayne Iba, and Kevin Thompson. An analysis of Bayesian classifiers. In AAAI-92, 1992.\\r\\nLeah S. Larkey and W. Bruce Croft. Combining classifiers\\r\\nin text categorization. In SIGIR-96, 1996.\\r\\nD. Lewis and W. Gale. A sequential algorithm for training\\r\\ntext classifiers. In SIGIR-94, 1994.\\r\\nDavid D. Lewis. An evaluation of phrasal and clustered\\r\\nrepresentations on a text categorization task. In SIGIR92, 1992.\\r\\nDavid Lewis. Naive (bayes) at forty: The independence\\r\\nasssumption in information retrieval. In ECML\\xe2\\x80\\x9998: Tenth\\r\\nEuropean Conference On Machine Learning, 1998.\\r\\nHang Li and Kenji Yamanishi. Document classification\\r\\nusing a finite mixture model. In Proceedings of the 35th\\r\\nAnnual Meeting of the Association for Computational Linguistics, 1997.\\r\\nRay Liere and Prasad Tadepalli. Active learning with committees for text categorization. In AAAI-97, 1997.\\r\\nAndrew McCallum, Ronald Rosenfeld, Tom Mitchell, and\\r\\nAndrew Ng. Improving text clasification by shrinkage in a\\r\\nhierarchy of classes. In ICML-98, 1998.\\r\\nTom M. Mitchell. Machine Learning. WCB/McGraw-Hill,\\r\\n1997.\\r\\nKamal Nigam, Andrew McCallum, Sebastian Thrun, and\\r\\nTom Mitchell. Learning to classify text from labeled and\\r\\nunlabeled documents. In AAAI-98, 1998.\\r\\nS. E. Robertson and K. Sparck-Jones. Relevance weighting of search terms. Journal of the American Society for\\r\\nInformation Science, 27:129\\xe2\\x80\\x93146, 1976.\\r\\nMehran Sahami, Susan Dumais, David Heckerman, and\\r\\nEric Horvitz. A bayesian approach to filtering junk e-mail.\\r\\nIn AAAI-98 Workshop on Learning for Text Categorization, 1998.\\r\\nMehran Sahami. Learning limited dependence Bayesian\\r\\nclassifiers. In KDD-96: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, pages 335\\xe2\\x80\\x93338. AAAI Press, 1996.\\r\\nV. Vapnik. Estimations of dependences based on statistical\\r\\ndata. Springer Publisher, 1982.\\r\\nYiming Yang and Jan Pederson. Feature selection in statistical learning of text categorization. In ICML-97, 1997.\\r\\n\\r\\n\\x0cacq\\r\\n\\r\\ncorn\\r\\n\\r\\n100\\r\\n\\r\\n100\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\n80\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\ncrude\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n100\\r\\n\\r\\n80\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\n100000\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\ngrain\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\nmoney-fx\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n100\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\n80\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\n10000\\r\\n\\r\\n100\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\ntrade\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\nwheat\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n100\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\nMultinomial\\r\\nMulti-variate Bernoulli\\r\\n\\r\\n80\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\nPrecision/Recall Breakeven Point\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\nearn\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n\\r\\n80\\r\\n\\r\\n60\\r\\n\\r\\n40\\r\\n\\r\\n20\\r\\n\\r\\n0\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n10\\r\\n\\r\\n100\\r\\n\\r\\n1000\\r\\nVocabulary Size\\r\\n\\r\\nFigure 6: The continuation of the Reuters results from Figure 5.\\r\\n\\r\\n10000\\r\\n\\r\\n100000\\r\\n\\r\\n\\x0c'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"DISCOUNT AND ADVANCE RATES -- Requests by twelve Reserve Banks to\\r\\nmaintain the existing primary credit rate; requests to renew the secondary and\\r\\nseasonal credit formulas.\\r\\n\\r\\nExisting rate and formulas approved.\\r\\nOctober 5, 2020.\\r\\n\\r\\nToday, Board members discussed economic and financial developments and\\r\\nissues related to possible policy actions. In connection with this discussion, Board\\r\\nmembers considered discounts and advances under the primary credit program (the\\r\\nprimary credit rate) and discussed, on a preliminary basis, their individual assessments\\r\\nof the appropriate rate and its communication, which would be discussed at the next\\r\\njoint meeting of the Board and the Federal Open Market Committee.\\r\\nSubject to review and determination by the Board of Governors, the directors\\r\\nof the Federal Reserve Banks of New York, Cleveland, Richmond, Atlanta, Chicago,\\r\\nKansas City, and Dallas had voted on September 24, 2020, and the directors of the\\r\\nFederal Reserve Banks of Boston, Philadelphia, St. Louis, Minneapolis, and San\\r\\nFrancisco had voted on October 1, to establish the primary credit rate at the existing\\r\\nlevel of 0.25 percent.\\r\\nNo sentiment was expressed by the Board at today's meeting for changing\\r\\nthe primary credit rate at this time, and the Board approved the establishment of the\\r\\nprimary credit rate at the existing level of 0.25 percent. The Board's action today on the\\r\\nprimary credit rate also included renewal of the existing formulas for calculating the\\r\\nrates applicable to discounts and advances under the secondary and seasonal credit\\r\\nprograms for all twelve Reserve Banks. As specified by the formula for the secondary\\r\\ncredit rate, this rate would be set 50 basis points above the primary credit rate. As\\r\\nspecified by the formula for the seasonal credit rate, this rate would be reset every two\\r\\nweeks as the average of the daily effective federal funds rate and the rate on threemonth CDs over the previous 14 days, rounded to the nearest 5 basis points.\\r\\n\\r\\nVoting for this action: Chair Powell, Vice Chair Clarida,\\r\\nVice Chair for Supervision Quarles, and\\r\\nGovernors Brainard and Bowman.\\r\\nBackground:\\r\\nOffice of the Secretary memorandum, October 2, 2020.\\r\\nImplementation: Transmissions from Ms. Misback to the Reserve Banks,\\r\\nOctober 5, 2020.\\r\\nPage 1\\r\\n\\r\\n\\x0cImplementation: Transmissions from Ms. Misback to the Reserve Banks,\\r\\nOctober 5, 2020.\\r\\nDISCOUNT AND ADVANCE RATES -- Requests by twelve Reserve Banks to\\r\\nmaintain the existing primary credit rate; requests to renew the secondary and\\r\\nseasonal credit formulas.\\r\\n\\r\\nExisting rate and formulas approved.\\r\\nOctober 26, 2020.\\r\\n\\r\\nToday, Board members discussed economic and financial developments and\\r\\nissues related to possible policy actions. In connection with this discussion, Board\\r\\nmembers considered discounts and advances under the primary credit program (the\\r\\nprimary credit rate) and discussed, on a preliminary basis, their individual assessments\\r\\nof the appropriate rate and its communication, which would be discussed at the joint\\r\\nmeeting of the Board and the Federal Open Market Committee (FOMC) next week.\\r\\nSubject to review and determination by the Board of Governors, the directors\\r\\nof the Federal Reserve Banks of Boston, Philadelphia, St. Louis, and Kansas City had\\r\\nvoted on October 15, 2020, and the directors of the Federal Reserve Banks of New\\r\\nYork, Cleveland, Richmond, Atlanta, Chicago, Minneapolis, Dallas, and San Francisco\\r\\nhad voted on October 22, to establish the primary credit rate at the existing level of\\r\\n0.25 percent.\\r\\nFederal Reserve Bank directors reported continued improvement in\\r\\neconomic conditions, while noting that some sectors remain deeply affected by the\\r\\npandemic. Several directors commented on the strength in residential real estate\\r\\nmarkets, including significant mortgage refinancing activity. Some directors reported a\\r\\npickup in retail spending, citing strong online sales but also improved foot traffic at\\r\\nstores outside of malls and urban areas. Labor market conditions varied across sectors\\r\\nand Districts. While some directors reported increased hiring and competition for\\r\\ncertain higher-skilled and entry-level positions, layoffs continued in other sectors,\\r\\nparticularly leisure and hospitality. Overall, directors were cautious about the pace of\\r\\nfuture improvements in the economy, given continued uncertainty about the evolution of\\r\\nthe pandemic and the potential implications for the outlook.\\r\\nThe directors of all twelve Federal Reserve Banks favored maintaining the\\r\\ncurrent primary credit rate at the existing level (0.25 percent). In light of the\\r\\nuncertainties associated with the pandemic, the directors judged that it would be\\r\\nappropriate for the FOMC to maintain the current stance of policy to continue to support\\r\\neconomic recovery and foster progress toward the FOMC's long-run goals of maximum\\r\\nemployment and stable prices.\\r\\nPage 2\\r\\n\\r\\n\\x0cNo sentiment was expressed by the Board at today's meeting for changing\\r\\nthe primary credit rate at this time, and the Board approved the establishment of the\\r\\nprimary credit rate at the existing level of 0.25 percent. The Board's action today on the\\r\\nprimary credit rate also included renewal of the existing formulas for calculating the\\r\\nrates applicable to discounts and advances under the secondary and seasonal credit\\r\\nprograms for all twelve Reserve Banks. As specified by the formula for the secondary\\r\\ncredit rate, this rate would be set 50 basis points above the primary credit rate. As\\r\\nspecified by the formula for the seasonal credit rate, this rate would be reset every two\\r\\nweeks as the average of the daily effective federal funds rate and the rate on threemonth CDs over the previous 14 days, rounded to the nearest 5 basis points.\\r\\n\\r\\nVoting for this action: Chair Powell, Vice Chair Clarida,\\r\\nVice Chair for Supervision Quarles, and\\r\\nGovernors Brainard and Bowman.\\r\\nBackground:\\r\\nOffice of the Secretary memorandum, October 23, 2020.\\r\\nImplementation: Transmissions from Ms. Misback to the Reserve Banks,\\r\\nOctober 26, 2020.\\r\\nMONETARY POLICY IMPLEMENTATION -- Interest rate on required and excess\\r\\nreserve balances unchanged; rates on discounts and advances unchanged;\\r\\nrenewal of secondary and seasonal credit formulas.\\r\\n\\r\\nApproved.\\r\\nNovember 5, 2020.\\r\\n\\r\\nIn a joint meeting of the Federal Open Market Committee (FOMC) and the\\r\\nBoard today, the FOMC decided to maintain the target range for the federal funds rate\\r\\nat 0 to 1/4 percent, effective November 6, 2020. Consistent with the FOMC's decision\\r\\nto leave the target range for the federal funds rate unchanged, the Board approved\\r\\nmaintaining the interest rate (0.10 percent) paid on required and excess reserve\\r\\nbalances, effective November 6, 2020. At today's meeting, the Board also approved the\\r\\nestablishment of the interest rate on discounts and advances made under the primary\\r\\ncredit program (the primary credit rate) at the existing level (0.25 percent).\\r\\nSubject to review and determination by the Board of Governors, the directors of\\r\\nthe Federal Reserve Banks of Boston, Philadelphia, Atlanta, Chicago, St. Louis, Kansas\\r\\nCity, and Dallas had voted on October 29, 2020, to establish the primary credit rate at\\r\\nPage 3\\r\\n\\r\\n\\x0cthe existing level of 0.25 percent.\\r\\nNo sentiment was expressed by the Board at today's meeting for changing the\\r\\nprimary credit rate at this time, and the Board approved the establishment of the primary\\r\\ncredit rate at the existing level of 0.25 percent. The Board's action today on the primary\\r\\ncredit rate also included renewal of the existing formulas for calculating the rates\\r\\napplicable to discounts and advances under the secondary and seasonal credit\\r\\nprograms. As specified by the formula for the secondary credit rate, this rate would be\\r\\nset 50 basis points above the primary credit rate. As specified by the formula for the\\r\\nseasonal credit rate, this rate would be reset every two weeks as the average of the\\r\\ndaily effective federal funds rate and the rate on three-month CDs over the previous\\r\\n14 days, rounded to the nearest 5 basis points.\\r\\n\\r\\nVoting for these actions: Chair Powell, Vice Chair Clarida,\\r\\nVice Chair for Supervision Quarles, and\\r\\nGovernors Brainard and Bowman.\\r\\nBackground:\\r\\nOffice of the Secretary memorandum, October 30, 2020.\\r\\nImplementation: FOMC Statement (with attached Implementation Note) and\\r\\ntransmissions from Ms. Misback to the Reserve Banks,\\r\\nNovember 5, 2020.\\r\\n\\r\\nPage 4\\r\\n\\r\\n\\x0c\"\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TD-IDF Vectorizer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'s</th>\n",
       "      <th>--</th>\n",
       "      <th>across</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>advanc</th>\n",
       "      <th>affect</th>\n",
       "      <th>also</th>\n",
       "      <th>applic</th>\n",
       "      <th>appropri</th>\n",
       "      <th>...</th>\n",
       "      <th>two</th>\n",
       "      <th>uncertainti</th>\n",
       "      <th>unchang</th>\n",
       "      <th>urban</th>\n",
       "      <th>vari</th>\n",
       "      <th>vice</th>\n",
       "      <th>vote</th>\n",
       "      <th>week</th>\n",
       "      <th>would</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.083293</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.052058</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.06247</td>\n",
       "      <td>0.083293</td>\n",
       "      <td>0.041646</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.020823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.083293</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.052058</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.06247</td>\n",
       "      <td>0.083293</td>\n",
       "      <td>0.041646</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.020823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         's        --    across    action     activ    advanc    affect  \\\n",
       "0  0.093704  0.031235  0.010412  0.083293  0.010412  0.093704  0.010412   \n",
       "1  0.093704  0.031235  0.010412  0.083293  0.010412  0.093704  0.010412   \n",
       "\n",
       "       also    applic  appropri  ...       two  uncertainti   unchang  \\\n",
       "0  0.052058  0.031235  0.031235  ...  0.031235     0.020823  0.031235   \n",
       "1  0.052058  0.031235  0.031235  ...  0.031235     0.020823  0.031235   \n",
       "\n",
       "      urban      vari     vice      vote      week     would      york  \n",
       "0  0.010412  0.010412  0.06247  0.083293  0.041646  0.093704  0.020823  \n",
       "1  0.010412  0.010412  0.06247  0.083293  0.041646  0.093704  0.020823  \n",
       "\n",
       "[2 rows x 212 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tfidf_tokens = vectorizer.get_feature_names()\n",
    "df_tfidfvect = pd.DataFrame(data = x.toarray(), columns = tfidf_tokens)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "df_tfidfvect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use them for:\n",
    "* Information extraction/transfer learning\n",
    "* Measure similarity (e.g. cosine) between words/clustering\n",
    "* Analogies\n",
    "* Machine Translation\n",
    "* Question Answering\n",
    "\n",
    "Algorithms:\n",
    "* Words: Word2vec, Glove, FastText, etc.\n",
    "* Sentences: Doc2vec, etc. \n",
    "\n",
    "There are pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microscope image of an iPhone screen.\n",
    "\n",
    "<img src=\"iphone-microscope.jpg\" style=\"width:200px;height:50;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer science, an image is represented by a 3D array of shape $(length, height, depth = 3)$. However, when you read an image as the input of an algorithm you convert it to a vector of shape $(length*height*3, 1)$. In other words, you \"unroll\", or reshape, the 3D array into a 1D vector.\n",
    "\n",
    "<img src=\"image2vector.png\" style=\"width:500px;height:300;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    length, height, depth = image.shape\n",
    "    v = image.reshape((length * height * depth, 1))   \n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print(\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
